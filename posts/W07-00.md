---
title: ðŸ’¥ Web Audio API & Responding to Text
published_at: 2025-04-17
snippet: Week 07 00
disable_html_sanitization: true
allow_math: true
---

<style>
  @import url('https://fonts.googleapis.com/css2?family=Cutive+Mono&display=swap');
  @import url('https://use.typekit.net/jyw5vxq.css');

h1, h3, h4, p, pre, ul, li, .notranslate {
  /* font-family: "Cutive Mono", monospace;
  font-weight: 700;
  font-style: normal; */

  font-family: "prestige-elite-std", monospace;
  font-weight: 600;
  font-style: normal;
  color:#CEB5D4;
}

 .text-gray-500, .markdown-body blockquote {color:#E872B0}
 .markdown-body {background-color:#102B53;}
  html {background-color:#102B53;}
  h1 {; font-weight: 800;}
  p, pre, ul {color:#7D9FC0;}
  .markdown-body a {color:#4E7AB1; text-decoration:underline;}

  .notranslate, text {
    color: #102B53;
    font-weight: 800;
  }


</style>

---

# Homework

### 1. how will you make the sound design for your AT2 function in a chaotic aesthetic register?Â  What does it mean to be chaotic in the sonic domain? In your discussion, please make reference to:

> Effective complexity, paying particular attention to:
>
> - structure - whatÂ *structures*Â our perception of sound?
> - noise - what differentiatesÂ noiseÂ fromÂ sound, or music?
> - voice - what makesÂ *voice*Â a separate category of sound?

> The role of de-familiarisation (as per Natalie Loveless' talkÂ [From Relational to Ecological Form](https://youtu.be/whzD1EPBVLk))

> Three examples, which can (but don't have to) be taken from the following list:
>
> - MyNoise Generators:Â [Jungle](https://mynoise.net/NoiseMachines/jungleNoiseGenerator.php)Â /Â [Water](https://mynoise.net/NoiseMachines/healingWaterSoundscapeGenerator.php)Â /Â [Fire](https://mynoise.net/NoiseMachines/fireNoiseGenerator.php)Â /Â [Thunder](https://mynoise.net/NoiseMachines/thunderNoiseGenerator.php)Â /Â [Storm](https://mynoise.net/NoiseMachines/stormSoundGenerator.php)
> - [Pink](https://dood.al/pinktrombone)
> - [How to Kill a Zombie.](https://lcld.xyz/240831_how_to_kill)

Effective complexity in itself is a range balance between high structure and high randomness. In the case of sound I'd say that is a state between fine-tuned wavelengths vs interference to this wavelength. Kind of like when adjusting a radio and you're trying to find the right wavelength to listen into the channel that you want you'll often encounter a lot of 'noise' before getting the right wavelength and you can hear the voice/sound a lot more clearly. With this understanding it could be said that noise is the 'random' and sound, the 'clean' wavelength is the 'structured'. Bringing this back to effective complexity, I'd say effective complexity in the sonic domain is a point of intersection between noise and sound. When effectively wielded it could be translated into music. Where, perhaps a genre like pop is a universal mid point between the two, but something like ballads would lean more towards structured and heavy metal leaning more towards noise.

The concept of de-familiarisation is a technique which presents familiar things in unfamiliar ways. This is to enhance the audience's perception and create new awareness of the subject. In this context, this would mean manipulating something familiar to create a fresh experience. In this sense, this concept could be wielded in a way which ensues chaos in the sonic domain.

The Jungle Noise Generator, which separates the jungle noises into the different categories, sub-bass, low-bass, bass, high-bass, low-mids, mids, high-mids, low-treble, treble, high-treble, and allows the user to adjust these categories in a way that defamiliarises the jungle sound. Through this process, it also in a way creates 'noise' even though it's technically just the different registers within the jungle sound itself.

Unlike the Jungle Noise Generator, the storm one categorises the sound track by the different parts and pairings that create the storm, with the broader categories being wind, rain & distant thunder. But likewise provides the user with a new and chaotic experience of "storm noise". (Though storm noise is already quite chaotic due to the unpredictable nature of the wind, rain and thunder)

'Pink' is similar in the way that it takes a very mundane sound, the human mouth, and separates it into a few key categories (structure), pitch, tongue location, voice (which is further separated into wobbly and 'always voice') though ultimately categorised by the parts of the mouth. Which the user manipulates via a click interaction on the visuals and affords a new experience of the sound. In this way, 'Pink' also creates a potential for chaos to ensue as the different categories are wielded by the user.

In relation to Assignment 2, I think that the sound that I've incorporated is already quite chaotic in nature, like the storm sounds for the storm noise generator. And in a similar nature, I think I could further enhance the sound experience by following the concept of de-familiarisation. Manipulating the sound to give it new context. I'm thinking to use a click interaction that will affect the volume at which the sound plays out to give it a de-centering experience. Kind of like a doppler effect but make it even more trippy to really effect the sense of grounding.

### 2. Implement an interactive sound design experiment in your blog.

> - you will need to get some form of user gesture for Web Audio API to run.
> - you can use a library, such asÂ [Tone.js](https://tonejs.github.io/)Â orÂ [Pizzicato.js](https://alemangui.github.io/pizzicato), or you can useÂ [Web Audio API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API), orÂ [AudioWorklet](https://developer.mozilla.org/en-US/docs/Web/API/AudioWorklet).
> - use a sinusoid to push your sound design into chaos and back every 24 seconds.
> - explain your code with the help of syntax-highlighted, commented code blocks
> - evaluate the success of your experiment with reference to your discussion in task 1

<div id="sound" style="margin-bottom: 5%;"> </div>

# Assignment 2

<iframe id="w07-00" src="https://sams4m-comm2747-at2.deno.dev/ver2/"></iframe>

> Third implementation of AT2.

After much research and debugging, I've finally found out why the shader wasn't working and for a pretty simple reason too; the renderer wasn't properly added to the DOM system. So it was kind of up in nowhere, which was also why the background coming out was just default white. I also adjusted the z index to -1 to make sure the shader is behind the moving network of spores. Orbit controls aren't working, though I think it may be because of the z index being set so the scene is running at the very back. I'll do some testing, but otherwise I think I would actually prefer to keep the torus at the back and zoomed in as it shows a more interesting structure as a background, but I'll be adding some rotation to add some texture and movement to the background.

The spores are also trailing because the background isn't being re-drawn every time (was removed so that the shader can be seen), so it's very much actually a simple process that is causing this scene to be rendered.

While it was implied this could be accepted as a creative submission, I think I want to add some more chaos variables to the code, as I've realised I have a new problem now -- the stars will eventually fill up the whole screen and the shader won't even be seen!

<script type="module">
const iframe = document.getElementById (`w07-00`)
iframe.width = iframe.parentNode.scrollWidth
iframe.height = iframe.width * 9 / 16 + 42
</script>

<div id="codeblock0"> </div>

---

<script id="script">
// get and format div element
const div  = document.getElementById ('sound');
div.width  = div.parentNode.scrollWidth;
div.style.height     = `${ div.width * 9 / 16 }px`;
div.style.backgroundColor = 'pink';

// get and suspend audio context
const audioContext = new AudioContext();
audioContext.suspend();

// define an async click handler function 
async function init_audio() {
  // wait for audio context to resume
  await audioContext.resume();
}

// OSCILLATOR NODE
// store a new oscillator node in a variable
const oscNode = audioContext.createOscillator();
// defining oscillator node type
oscNode.type = 'sawtooth';

// frequency
oscNode.frequency.value = 330;

// store new gain node in a variable
const ampNode = audioContext.createGain();

// set gain default to 0 (no sound)
ampNode.gain.value = 0;


// connect the oscillator node to the gain node
oscNode.connect(ampNode);

// connect the gain node to audio output device on audio context
ampNode.connect(audioContext.destination);

// start the oscillator
oscNode.start();

// amplitude modulation variables
let modulationStartTime = 0;
// 1/24 Hz frequency 
const modulationFrequency = 1/24; 


// TOGGLE SOUND
// define a sound status var
let soundStatus = false;

// toggle sound function 
function toggleSound() {
  // if sound status value is off
  if (soundStatus === false) {
    // modulation start time
    modulationStartTime = audioContext.currentTime;

    // set the value to true
    soundStatus = true;

    // start amplitude modulation
    modulateAmplitude();

    // change background colour
    div.style.backgroundColor = 'deeppink';
  }
  // if sound status value is on
  else if (soundStatus === true) {

    // set the value to false
    soundStatus = false;
      
    // change background colour
    div.style.backgroundColor = 'pink';
  }
}

// anonymous function click handler 
div.onclick = () => {
  // if the audio context is still suspended
  // resume the audio context first
  if (audioContext.state != 'running') init_audio ();

  // then call the toggle sound function
  toggleSound();
}

// function to apply amplitude modulation
function modulateAmplitude() {
  // declaring time now when function called
  const now = audioContext.currentTime;
  // calculating elapsed time
  const elapsedTime = now - modulationStartTime;
  
  // modulation - creates values between 0 and 1
  // starting from the middle 0.5
  // sin produces a wave between -1 and 1
  // therefore * 0.5 to make it -0.5 to 0.5
  // +0.5 makes ot 0 to 1
  // angle = 2 * Math.PI * modulationFrequency * elapsedTime
  // 2 * Math.PI = full circle 
  // modulationFrequecy = 1/24 means we complete a cycle every 24 s
  // elapsedTime = time since we started oscillation 
  const modulation = 0.5 + 0.5 * Math.sin(2 * Math.PI * modulationFrequency * elapsedTime);
  
  // apply to gain (with base amplitude of 0.2)
  ampNode.gain.value = 0.2 * modulation;
  
  // next modulation update
  if (soundStatus === true) {
    requestAnimationFrame(modulateAmplitude);
  } else {
    ampNode.gain.value = 0;
  }
}
</script>

<!-- AT2 VER 2 ------------------------------------------------------------------------------- -->
<script id="ver2">
import { drawStar } from "/drawStar.js";
import { colours } from "./colour.js";
import * as THREE from "/three.js";
import { OrbitControls } from "/OrbitControls.js";

// document styling
document.body.style.margin = 0;
document.body.style.overflow = `hidden`;

// setting up canvas
const cnv = document.getElementById(`canvas`);
cnv.width = window.innerWidth;
cnv.height = window.innerHeight;

const ctx = cnv.getContext(`2d`);

// Set up scene
const scene = new THREE.Scene();
scene.background = new THREE.Color(0x7252dc);
const camera = new THREE.PerspectiveCamera(
  70,
  cnv.width / cnv.height,
  0.01,
  10
);
camera.position.z = 2;
const renderer = new THREE.WebGLRenderer({ antialias: true });
const clock = new THREE.Clock();

// Setup renderer
// size of renderer
renderer.setSize(window.innerWidth, window.innerHeight);
document.body.appendChild(renderer.domElement);

// styling
renderer.domElement.style.position = "absolute";
renderer.domElement.style.top = "0";
renderer.domElement.style.left = "0";
renderer.domElement.style.zIndex = "-1";

// set up orbit controls
const controls = new OrbitControls(camera, renderer.domElement);
controls.enableDamping = true;

// ----------------------------------------------------------------------- //
// sound
const audioContext = new AudioContext();
// suspend until click
audioContext.suspend();
// volume controls
const gainNode = audioContext.createGain();
// audio
const audioE = new Audio("/weird.wav");
audioE.load();
const source = audioContext.createMediaElementSource(audioE);
// connect audio element to gain node
source.connect(gainNode);
// Connect Gain Node to Destination
gainNode.connect(audioContext.destination);
// preset value ; set at 50%
gainNode.gain.value = 0.5;

// ----------------------------------------------------------------------- //
// GLOBAL VARS
let particleArr = [],
  coli = 0,
  mesh;

// ----------------------------------------------------------------------- //
// SHADER MATERIAL
const shaderMaterial = new THREE.ShaderMaterial({
  uniforms: {
    u_time: { value: 0.0 },
  },
  vertexShader: `
   uniform float u_time;
   varying vec3 vNormal;
   varying vec3 vPosition;
   
         void main() {
           vNormal = normal;
   
           // Animate the vertices
           vec3 newPosition = position;
           float displacement = sin(position.y * 18.0 + u_time * 2.0) * 0.1;
           newPosition += normal * displacement;
   
           vPosition = newPosition;
           gl_Position = projectionMatrix * modelViewMatrix * vec4(newPosition, 1.0);
         }
   
   `,
  fragmentShader: `
   uniform float u_time;
   varying vec3 vNormal;
   varying vec3 vPosition;
   
         void main() {
           // Create a color based on the position and normal
           // multiplying vpos and vec3 makes the pattern and phases more intense
           // creating a moire effect
           vec3 color = 1.0 + 1.5 * sin(u_time * vPosition * 2.0 * vec3(0, 5, 4));
           // vec3 color = 1.0 - (((u_time % 9) % 1) + vPosition + vec3(0, 5, 4));
   
   
           // Add some shading based on the normals
           float lighting = dot(normalize(vNormal), normalize(vec3(1.0, 1.0, 1.0)));
           lighting = 0.1 + lighting * 0.5;
   
           gl_FragColor = vec4(color * lighting, 1.0);
         }
   
   `,
  side: THREE.DoubleSide,
});

// ----------------------------------------------------------------------- //
// MOUSE OBJ; tracks mouse x, y coord
// grab mouse position
let mouse = {
  x: null,
  y: null,
  // the radius will give the particles an area around the
  // mouse which they interact/react with
  radius: (cnv.height / 200) * (cnv.width / 200),
};

// event listener will fire every time the mouse moves and
// fills the mouse object
window.addEventListener("mousemove", function (event) {
  mouse.x = event.x;
  mouse.y = event.y;
});

// ----------------------------------------------------------------------- //
// CLASS: PARTICLE
class Particle {
  constructor(x, y, dirX, dirY, size, npoint) {
    // x coordinate
    this.x = x;
    // y coordinate
    this.y = y;
    // velocity along x
    this.dirX = dirX;
    // velocity along y
    this.dirY = dirY;
    // particle size
    this.size = size;
    // number of points on star
    this.n = npoint;

    // star particle
    this.starParticle = new drawStar(
      this.x,
      this.y,
      this.size - 2,
      this.size + 7,
      this.n
    );

    // Configure star oscillation
    this.starParticle.setOscillation(
      0.7,
      Math.random() * (3 - 2.5) + 2.5,
      0.2 + Math.random() * 0.6
    );
  }

  // method to draw an individual particle
  draw() {
    // colour
    let colour = "#" + colours[coli];
    ctx.fillStyle = colour;

    // Update star position to match particle
    this.starParticle.cx = this.x;
    this.starParticle.cy = this.y;

    this.starParticle.update();
  }

  // check particle pos, mouse pos, move the particle and draw
  update() {
    // check particle is still within canvas
    if (this.x > cnv.width || this.x < 0) {
      // turn direction around
      this.dirX = -this.dirX;
    }
    if (this.y > cnv.height || this.y < 0) {
      // turn direction around
      this.dirY = -this.dirY;
    }

    // check for collision detection between mouse & particles
    // circle collision
    // ref: https://developer.mozilla.org/en-US/docs/Games/Techniques/2D_collision_detection

    // checking distance between mouse & particle center point
    let dx = mouse.x - this.x;
    let dy = mouse.y - this.y;

    // a^2 + b^2 = c^2
    let dist = Math.sqrt(dx * dx + dy * dy);

    // checking that particle is far enough from edge of cvs
    // or it'll get stuck
    if (dist < mouse.radius + this.size) {
      // allowing buffer area of particle size (this.size) * 10
      // if mouse is left of particle
      if (mouse.x < this.x && this.x < cnv.width - this.size * 10) {
        // move particle to the right
        this.x += 10;
      }
      // if mouse is right of particle
      if (mouse.x > this.x && this.x > this.size * 10) {
        // move particle to the left
        this.x -= 10;
      }
      // if mouse is above particle
      if (mouse.y < this.y && this.y < cnv.height - this.size * 10) {
        // move particle down
        this.y += 10;
      }
      // if mouse is under particle
      if (mouse.y > this.y && this.y > this.size * 10) {
        // move particle up
        this.x -= 10;
      }
    }
    // moving all the other particles that aren't colliding along too
    this.x += this.dirX;
    this.y += this.dirY;
    // calling draw method to update;
    this.draw();
  }
}

// ----------------------------------------------------------------------- //
// INIT: RANDOMISE VALUES FOR PARTICLES
function init() {
  // number of particles
  let numOf = (cnv.height * cnv.width) / 8000;

  for (let i = 0; i < numOf; i++) {
    // size of particle = random val between 1 & 5
    let size = Math.random() * (5 - 1) + 1;
    // x coord = random value between 0 and cnv width
    // with size * 2 as buffer so it doesn't get stuck
    let x =
      Math.random() * (cnv.width - size * 2 - (0 + size * 2)) + 0 + size * 2;
    let y =
      Math.random() * (cnv.height - size * 2 - (0 + size * 2)) + 0 + size * 2;

    // particle movement speed between -0.5 and 0.5
    let dirX = Math.random() * (1 + 0.5) - 0.5;
    let dirY = Math.random() * (1 + 0.5) - 0.5;

    // number of points on star
    // random value between 7 and 15
    let n = Math.random() * (15 - 7) + 7;

    // pushing a new instance of Particle with the above defined values
    // into particle array
    particleArr.push(new Particle(x, y, dirX, dirY, size, n));
  }

  // // create a torus knot
  const geometry = new THREE.TorusKnotGeometry(5, 3, 40, 15, 14, 4);
  mesh = new THREE.Mesh(geometry, shaderMaterial);
  // Clear scene of previous meshes
  if (mesh) scene.remove(mesh);
  scene.add(mesh);

  // create plane
  //   const geometry = new THREE.PlaneGeometry(1.6, 0.9);
  //   const mesh = new THREE.Mesh(geometry, shaderMaterial);
  //   scene.add(mesh);

  // add light
  const ambientLight = new THREE.AmbientLight(0xffffff, 0.5);
  scene.add(ambientLight);
}

// FUNC: CONNECT
// checking if particles are close enough to connect
function connect() {
  let opacityVal = 0.7;
  // go through every particle
  for (let a = 0; a < particleArr.length; a++) {
    // going through consecutive particles in array
    for (let b = 0; b < particleArr.length; b++) {
      let dist =
        (particleArr[a].x - particleArr[b].x) *
          (particleArr[a].x - particleArr[b].x) +
        (particleArr[a].y - particleArr[b].y) *
          (particleArr[a].y - particleArr[b].y);

      // the smaller the number, the longer the lines,
      // the more particles connected
      if (dist < (cnv.width / 2) * (cnv.height / 2)) {
        opacityVal = 0.7 - dist / 9000;
        ctx.strokeStyle = "rgba(51, 65, 57," + opacityVal + ")";
        ctx.lineWidth = 1;
        //console.log(ctx.lineWidth);
        ctx.beginPath();
        ctx.moveTo(particleArr[a].x, particleArr[a].y);
        ctx.lineTo(particleArr[b].x, particleArr[b].y);
        ctx.stroke();
      }
    }
  }
}

// ----------------------------------------------------------------------- //

// ANIMATION LOOP
function animate() {
  // BACKGROUND STYLE
  // clearing previous frame
  //   ctx.clearRect(0, 0, innerWidth, innerHeight);
  //   //ctx.fillStyle = "rgb(255 141 161)";
  //   ctx.fillStyle = "#7252DC";
  //   ctx.fillRect(0, 0, innerWidth, innerHeight);

  // Rotate three.js scene
  if (mesh) {
    mesh.rotation.x += 0.005;
    mesh.rotation.y += 0.01;
  }

  // shader update
  shaderMaterial.uniforms.u_time.value = clock.getElapsedTime();
  // render scene
  renderer.render(scene, camera);

  // update orbit controls
  controls.update();

  // update each star particle
  particleArr.forEach((e) => {
    e.update();
  });

  // call the connect func to draw lines
  connect();

  requestAnimationFrame(animate);
}

// call init fill array with randomised particles
init();
// call animate
animate();

// ----------------------------------------------------------------------- //
// web responsive
onresize = () => {
  cnv.width = innerWidth;
  cnv.height = innerHeight;
  mouse.radius = (cnv.height / 200) * (cnv.width / 200);

  // Update renderer and camera
  renderer.setSize(window.innerWidth, window.innerHeight);
  camera.aspect = window.innerWidth / window.innerHeight;
  camera.updateProjectionMatrix();

  init();
};

// mouse out event
// particles stop trying to interact with mouse when it leaves canvas
window.addEventListener("mouseout", function (mouse_event) {
  mouse.x = undefined;
  mouse.y = undefined;
});

// new var to hold new colour index
let newColi;
cnv.addEventListener("click", function cnvClicked() {
  console.log("screen clicked");
  // COLOUR
  // change colour index
  coli = coliRandomiser();
  console.log(coli);

  // SOUND
  if (audioContext.state == "suspended") {
    audioContext.resume();
  } else {
    audioE.play();
    let soundRatio = mouse.x / cnv.width;

    gainNode.gain.value = soundRatio;
  }
});

// FUNC: RANDOM COLOUR INDEX
function coliRandomiser() {
  // compute random colour index
  newColi = Math.floor(Math.random() * colours.length);

  // if the new random index == the current index number
  // call the function again to get a new random index number
  // that is different
  if (newColi == coli) {
    console.log("call recursive");
    return coliRandomiser();
  } else {
    // return new random index
    //randCol= r;
    return newColi;
  }
}
</script>

<script type="module">
   import codeBlockRenderer from "/scripts/codeblock_renderer.js"
   codeBlockRenderer (document, `script`, `sound`)
</script>

<script type="module">
   import codeBlockRenderer from "/scripts/codeblock_renderer.js"
   codeBlockRenderer (document, `ver2`, `codeblock0`)
</script>
