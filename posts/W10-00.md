---
title: üå† Mycelial Creativity
published_at: 2025-05-15
snippet: Week 10 00
disable_html_sanitization: true
allow_math: true
---

<style>
  .markdown-body h1, .markdown-body h3 {font-weight: 300;}
  p, ul {color:#3A6FD7;}

  .int-style {
  --color-primary:rgb(161, 161, 161);
  --color-background: #ffffff;
  --color-canvas-default: #ffffff;
  --color-foreground: #1e1e1e;
  --color-text: #1e1e1e;
  --color-muted-foreground:rgb(95, 95, 95);

  .markdown-body {background-color:#ffffff;}
  .markdown-body h1 {color:#1e1e1e;}

  }
</style>

---

<button id="int-btn" class="rounded-md p-2 bg-transparent border border-primary text-foreground hover:#7d9fc0">Make Me Interesting üåßÔ∏è</button>

<script>
const intBtn = document.querySelector("#int-btn");
console.log(intBtn);

let interesting = false;

intBtn.addEventListener("click", function () {
  console.log('button clicked');

  if (interesting === false){
    document.documentElement.classList.add('int-style');
    interesting = true;
  } else if (interesting === true){
    document.documentElement.classList.remove('int-style');
    interesting = false;
  }

});
</script>

---

# Homework

> - brainstorm a way you might incorporate¬†[WebRTC API](https://developer.mozilla.org/en-US/docs/Web/API/WebRTC_API)¬†or¬†[WebSockets API](https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API)¬†into your idea for AT3.
> - what technical aspects would you need to learn about if you were to implement this?
> - what else would you need to learn / do that would make this feasible?
> - what would your project gain from such an incorporation?

> - Please refer to the concept of mycelial creativity in your answer, if you can.

> - you are allowed to use AI assistance for this homework task.
> - post this discussion to your blog along with any diagrams or code blocks that may help you explain things.

\*\* The idea had changed the class after this so I had adjusted the homework response to fit the final at3 idea/response. Previously I had discussed ideas on using WebRTC for live streaming to an audience.

Both WebRTC and WebSockets are a way for web tech to communicate in real time; rtc.

WebSockets provide a consistent communication channel between the client and server over a single TCP connection. Therefore the client and server can send data to each other at anytime. It'd be good fro chat applications, collaborative editing and real-time updates/notifications.

WebRTC allows for direct peer to peer communication between browsers without the need of going through a server first. Making it good for real-time media transmission like video and voice calls and streaming.

I wouldn't necessarily require either per se, however, using WebRTC to integrate Touch Designer could allow for more possibilities in live interaction / networking between myself and the other creatives around me, helping to further nurture the creative network that is mycelial creativity.

I had done some research but found that while there is a possibility; touch designer has a WebRTC and WebSocket node, though it seems that it hasn't been commonly integrated or used as there aren't many tutorials and are all quite dated. But Those that have, have primarily used it to control Touch designer parameters from the web; allowing for a more interactive experience.

Through my digging, it seems that you could potentially use WebRTC/WebSockets to essentially live stream a Touch Designer output onto the web and embed the project that way. Though, as there isn't much material on this it would take a lot of time and trial and error to get it working as I've never really done anything like this.

I did find a [tutorial](https://derivative.ca/community-post/experience-webrtc-and-webrtc-remote-panel-new-webrtc-remote-panel-web-demo/67004) and [github template](https://github.com/TouchDesigner/WebRTC-Remote-Panel-Web-Demo#getting-a-development-certificate) by Touch Designer themselves though, which would be a good starting point.

This is their [remote panel web demo](https://touchdesigner.github.io/WebRTC-Remote-Panel-Web-Demo/).

I also asked claude.ai for help, and they were able to give documentation with 4 different methods to achieve this -- so I think it's safe to say that it's feasible, just not commonly practiced.

---

# Documentation given from Claude.ai: TouchDesigner to Web Streaming with WebRTC

I've created a comprehensive guide for streaming TouchDesigner to websites using WebRTC. Here are the key approaches:

**Quick Start (Easiest):**

- Use OBS to capture TouchDesigner output
- Stream via services like Millicast, Agora, or Daily.co
- Embed the stream in your website with simple JavaScript

**Advanced Options:**

- Direct TouchDesigner WebRTC implementation using Python and WebSockets
- NDI integration for professional workflows
- Custom streaming solutions with full control

**Key Considerations:**

- **Latency**: Hardware encoding and optimized settings can achieve sub-100ms latency
- **Quality**: Balance between visual fidelity and network bandwidth
- **Scalability**: CDN integration for multiple viewers
- **Security**: HTTPS/WSS required for production deployments

The method you choose depends on your specific needs:

- **Simple demo**: OBS + cloud service
- **Interactive applications**: Custom WebRTC implementation
- **Professional broadcast**: NDI-based solution
- **High performance**: Direct GPU encoding with minimal latency

## Overview

Streaming TouchDesigner content to a website using WebRTC involves capturing the TouchDesigner output and transmitting it as a real-time video stream. Here are the main approaches:

## Method 1: Using OBS + WebRTC Services

### Step 1: Setup TouchDesigner Output

1. In TouchDesigner, create your visual content
2. Use a¬†**Window COMP**¬†or¬†**Render TOP**¬†for output
3. Set your desired resolution (e.g., 1920√ó1080)
4. Enable full-screen or windowed output as needed

### Step 2: Capture with OBS Studio

1. Install OBS Studio
2. Add¬†**Window Capture**¬†or¬†**Display Capture**¬†source
3. Select your TouchDesigner window/output
4. Configure output settings:
   - Video: 1920√ó1080 @ 30fps (or your preference)
   - Encoder: x264 or hardware encoder

### Step 3: Stream via WebRTC Service

Use services like:

- **Millicast**¬†(Dolby.io)
- **Agora**
- **Daily.co**
- **Whereby Embedded**

#### Example with Millicast:

javascript

```javascript
// HTML page to receive stream
<!DOCTYPE html>
<html>
<head>
    <script src="https://cdn.millicast.com/packages/millicast-sdk/0.1.26/millicast.umd.js"></script>
</head>
<body>
    <video id="video" autoplay muted></video>
    <script>
        const streamName = 'your-stream-name';
        const accountId = 'your-account-id';

        const viewer = new millicast.View(streamName, {
            streamAccountId: accountId
        });

        viewer.on('track', (event) => {
            document.getElementById('video').srcObject = event.streams[0];
        });

        viewer.connect();
    </script>
</body>
</html>
```

## Method 2: Direct TouchDesigner WebRTC (Advanced)

### Using TouchDesigner's Web Server

TouchDesigner has built-in web server capabilities:

1. **Add Web Server DAT**
   - Set port (e.g., 8080)
   - Configure routes
2. **Create WebSocket Connection**

   python

   ```python
   # In TouchDesigner Execute DAT
   import websocket
   import json

   def sendFrame():
       # Get TOP data
       top = op('render1')
       # Convert to base64 or use other method
       # Send via WebSocket
   ```

3. **Web Client Code**

   javascript

   ```javascript
   const ws = new WebSocket("ws://localhost:8080");

   ws.onmessage = function (event) {
     const data = JSON.parse(event.data);
     // Handle received frame data
     updateCanvas(data);
   };
   ```

## Method 3: Using NDI + Browser Integration

### Setup NDI Output in TouchDesigner

1. Add¬†**NDI Out TOP**
2. Set stream name
3. Configure resolution and format

### Browser Integration

Use NDI-enabled browsers or conversion tools:

javascript

```javascript
// Using NDI WebRTC Bridge
const ndiStream = new NDIWebRTCBridge({
  streamName: "TouchDesigner Output",
  resolution: "1920x1080",
});

ndiStream.connect().then((stream) => {
  document.getElementById("video").srcObject = stream;
});
```

## Method 4: Custom WebRTC Implementation

### TouchDesigner Side (Python)

python

```python
# In Execute DAT
import asyncio
import websockets
import base64
import cv2
import numpy as np

class WebRTCStreamer:
    def __init__(self):
        self.clients = set()

    async def register(self, websocket):
        self.clients.add(websocket)

    async def unregister(self, websocket):
        self.clients.remove(websocket)

    async def send_frame(self, frame_data):
        if self.clients:
            message = {
                'type': 'frame',
                'data': base64.b64encode(frame_data).decode()
            }
            await asyncio.gather(
                *[client.send(json.dumps(message)) for client in self.clients],
                return_exceptions=True
            )

# Usage in TouchDesigner
def onFrameEnd(frame):
    top = op('render1')
    # Get frame data and send
    streamer.send_frame(top.numpyArray())
```

### Web Client

html

```html
<!DOCTYPE html>
<html>
  <head>
    <title>TouchDesigner WebRTC Stream</title>
  </head>
  <body>
    <canvas id="canvas"></canvas>
    <script>
      const canvas = document.getElementById("canvas");
      const ctx = canvas.getContext("2d");
      const ws = new WebSocket("ws://localhost:8765");

      ws.onmessage = function (event) {
        const data = JSON.parse(event.data);
        if (data.type === "frame") {
          const img = new Image();
          img.onload = function () {
            ctx.drawImage(img, 0, 0);
          };
          img.src = "data:image/jpeg;base64," + data.data;
        }
      };

      ws.onopen = function () {
        console.log("Connected to TouchDesigner stream");
      };
    </script>
  </body>
</html>
```

## Performance Optimization

### TouchDesigner Settings

- Use¬†**Performance Monitor**¬†to check frame rates
- Optimize¬†**Render TOP**¬†resolution
- Use¬†**GPU acceleration**¬†where possible
- Consider¬†**Level of Detail**¬†for complex scenes

### Network Optimization

javascript

```javascript
// Adaptive bitrate streaming
const connection = new RTCPeerConnection({
  iceServers: [{ urls: "stun:stun.l.google.com:19302" }],
});

// Adjust quality based on network conditions
function adjustQuality(stats) {
  if (stats.packetsLost > threshold) {
    // Reduce quality
    sender.setParameters({
      encodings: [
        {
          maxBitrate: 500000, // 500 kbps
        },
      ],
    });
  }
}
```

## Latency Considerations

### Minimize Latency:

1. **Hardware Encoding**: Use GPU encoders (NVENC, QuickSync)
2. **Low Latency Codecs**: H.264 with tune=zerolatency
3. **Buffer Settings**: Minimize buffering on both ends
4. **Network**: Use wired connections when possible

### TouchDesigner Optimization:

python

```python
# Reduce internal latency
op('render1').par.bufferswap = 0  # Immediate swap
op('window1').par.vsync = 0       # Disable VSync
```

## Security Considerations

### HTTPS/WSS Requirements

Modern browsers require secure connections for WebRTC:

javascript

```javascript
// Use secure WebSocket for production
const ws = new WebSocket("wss://yourdomain.com:8765");
```

### CORS Configuration

python

```python
# In TouchDesigner Web Server
headers = {
    'Access-Control-Allow-Origin': '*',
    'Access-Control-Allow-Methods': 'GET, POST, OPTIONS',
    'Access-Control-Allow-Headers': 'Content-Type'
}
```

## Testing and Debugging

### Network Testing Tools

- **WebRTC Internals**: chrome://webrtc-internals/
- **Network Analysis**: Wireshark for packet inspection
- **Latency Testing**: Custom ping/pong messages

### TouchDesigner Debugging

python

```python
# Monitor frame rates and performance
def logPerformance():
    fps = op('perform1')['fps']
    print(f"Current FPS: {fps}")

# Check network statistics
def checkNetwork():
    bytes_sent = op('websocket1').par.bytessent
    print(f"Bytes sent: {bytes_sent}")
```

## Production Deployment

### Scalability Solutions

- **CDN Integration**: Use services like AWS CloudFront
- **Load Balancing**: Multiple TouchDesigner instances
- **Edge Computing**: Deploy closer to end users

### Monitoring

javascript

```javascript
// Client-side monitoring
const monitor = {
  startTime: Date.now(),
  framesReceived: 0,

  logStats: function () {
    const duration = (Date.now() - this.startTime) / 1000;
    const fps = this.framesReceived / duration;
    console.log(`Average FPS: ${fps.toFixed(2)}`);
  },
};
```

## Troubleshooting Common Issues

### Connection Problems

- Check firewall settings
- Verify WebSocket/WebRTC ports are open
- Test with local connections first

### Performance Issues

- Monitor CPU/GPU usage in TouchDesigner
- Check network bandwidth utilization
- Optimize video encoding settings

### Browser Compatibility

- Test across different browsers
- Use WebRTC adapter.js for compatibility
- Implement fallbacks for unsupported features

This guide provides multiple approaches from simple OBS-based solutions to advanced custom implementations. Choose the method that best fits your technical requirements and latency needs.

---

I asked claude to go into further detail for Method 3 and this was the response:

## Method 3 in further detail:

**Key Components:**

1. **TouchDesigner NDI Setup**: Complete configuration of NDI Out TOP with advanced Python scripting for dynamic control
2. **Three Bridge Options**:
   - **OBS + NDI Plugin**: Easiest professional solution
   - **Custom Node.js Bridge**: Full control with JavaScript implementation
   - **Commercial Solutions**: NDI Bridge and OBS.Live integration
3. **Advanced Web Client**: Full-featured HTML5 canvas client with:
   - Real-time frame rendering
   - FPS and latency monitoring
   - Quality controls
   - Auto-reconnection
   - Fullscreen support
4. **WebRTC Integration**: Ultra-low latency option using WebRTC data channels and peer connections
5. **Performance Optimization**: Adaptive quality system that automatically adjusts based on system performance
6. **Monitoring & Debugging**: Comprehensive logging and statistics tracking

**Advantages of NDI Method:**

- **Professional Quality**: Broadcast-grade video transmission
- **Low Latency**: Can achieve sub-frame latency on local networks
- **Scalability**: NDI can handle multiple concurrent streams
- **Audio Support**: Built-in audio streaming capabilities
- **Network Efficiency**: Optimized for IP networks

**Use Cases:**

- Live performance streaming
- Interactive installations
- Broadcast integration
- Multi-screen displays
- Remote collaboration

## Method 3: Using NDI + Browser Integration (Detailed)

NDI (Network Device Interface) is a professional video-over-IP standard that provides high-quality, low-latency streaming. This method offers excellent quality and performance for TouchDesigner web streaming.

### Step 1: Setup NDI Output in TouchDesigner

#### Configure NDI Out TOP

1. **Add NDI Out TOP** to your network

   ```
   Right-click in Network Editor ‚Üí Add Operator ‚Üí TOP ‚Üí NDI Out TOP
   ```

2. **NDI Out TOP Parameters:**

   ```
   Stream Name: "TouchDesigner_Stream"
   Active: On
   Resolution: Custom or match input
   Format: BGRA8 (recommended for quality)
   Compression: None (for lowest latency) or H.264 (for bandwidth)
   Frame Rate: 30 or 60 fps
   Audio: On (if you want audio)
   ```

3. **Connect your render chain:**

   ```
   [Your TOPs] ‚Üí [NDI Out TOP]
   ```

#### Advanced NDI Configuration

python

```python
# In TouchDesigner Execute DAT for dynamic NDI control
def updateNDISettings():
    ndi_out = op('ndiout1')

    # Dynamic stream naming
    ndi_out.par.streamname = f"TD_Stream_{project.name}"

    # Adaptive quality based on network
    network_quality = checkNetworkQuality()
    if network_quality < 0.5:
        ndi_out.par.compression = 'h264'
        ndi_out.par.quality = 75
    else:
        ndi_out.par.compression = 'none'

    # Monitor stream status
    if ndi_out.par.connected:
        print(f"NDI stream active: {ndi_out.par.streamname}")
    else:
        print("NDI stream disconnected")

# Call periodically
run("updateNDISettings()", delayFrames=300)  # Every 10 seconds at 30fps
```

### Step 2: NDI to WebRTC Bridge Solutions

#### Option A: Using OBS with NDI Plugin

1. **Install OBS NDI Plugin:**
   - Download from [OBS NDI Plugin GitHub](https://github.com/Palakis/obs-ndi)
   - Install and restart OBS
2. **Configure OBS NDI Source:**

   ```
   Sources ‚Üí Add ‚Üí NDI‚Ñ¢ Source
   Source Name: TouchDesigner_Stream
   Bandwidth: Highest
   Sync: Network
   ```

3. **Stream via OBS WebRTC:**
   - Use OBS WebRTC plugin or services like:
     - **Millicast (Dolby.io)**
     - **Amazon IVS**
     - **Wowza Streaming Cloud**

#### Option B: Custom NDI to WebRTC Bridge

**Server-side Bridge (Node.js):**

javascript

```javascript
// ndi-webrtc-bridge.js
const NDI = require("@granikos/node-ndi");
const express = require("express");
const WebSocket = require("ws");
const { createCanvas, loadImage } = require("canvas");

class NDIWebRTCBridge {
  constructor(options = {}) {
    this.streamName = options.streamName || "TouchDesigner_Stream";
    this.port = options.port || 8080;
    this.wsPort = options.wsPort || 8081;
    this.clients = new Set();

    this.setupNDI();
    this.setupWebServer();
    this.setupWebSocket();
  }

  setupNDI() {
    // Initialize NDI
    if (!NDI.initialize()) {
      console.error("Failed to initialize NDI");
      return;
    }

    // Find NDI sources
    const finder = new NDI.Finder(true);
    finder.on("sources", (sources) => {
      console.log("Available NDI sources:", sources);

      // Find TouchDesigner stream
      const tdSource = sources.find((s) => s.name.includes(this.streamName));

      if (tdSource) {
        this.connectToNDISource(tdSource);
      }
    });
  }

  connectToNDISource(source) {
    console.log(`Connecting to NDI source: ${source.name}`);

    this.receiver = new NDI.Receiver({
      source: source,
      colorFormat: NDI.COLOR_FORMAT_BGRX_BGRA,
      bandwidth: NDI.BANDWIDTH_HIGHEST,
    });

    this.receiver.on("video", (videoFrame) => {
      this.processVideoFrame(videoFrame);
    });

    this.receiver.on("audio", (audioFrame) => {
      this.processAudioFrame(audioFrame);
    });
  }

  processVideoFrame(frame) {
    // Convert NDI frame to web-compatible format
    const canvas = createCanvas(frame.width, frame.height);
    const ctx = canvas.getContext("2d");

    // Create ImageData from NDI frame
    const imageData = ctx.createImageData(frame.width, frame.height);

    // Copy NDI frame data (BGRA to RGBA conversion)
    for (let i = 0; i < frame.data.length; i += 4) {
      imageData.data[i] = frame.data[i + 2]; // R
      imageData.data[i + 1] = frame.data[i + 1]; // G
      imageData.data[i + 2] = frame.data[i]; // B
      imageData.data[i + 3] = frame.data[i + 3]; // A
    }

    ctx.putImageData(imageData, 0, 0);

    // Convert to base64 and send to clients
    const base64Frame = canvas.toDataURL("image/jpeg", 0.8);
    this.broadcastFrame(base64Frame);
  }

  broadcastFrame(frameData) {
    const message = JSON.stringify({
      type: "video-frame",
      data: frameData,
      timestamp: Date.now(),
    });

    this.clients.forEach((client) => {
      if (client.readyState === WebSocket.OPEN) {
        client.send(message);
      }
    });
  }

  setupWebSocket() {
    this.wss = new WebSocket.Server({ port: this.wsPort });

    this.wss.on("connection", (ws) => {
      console.log("Client connected");
      this.clients.add(ws);

      ws.on("close", () => {
        console.log("Client disconnected");
        this.clients.delete(ws);
      });

      ws.on("message", (message) => {
        const data = JSON.parse(message);
        if (data.type === "request-frame") {
          // Send current frame immediately
          this.sendCurrentFrame(ws);
        }
      });
    });
  }

  setupWebServer() {
    const app = express();
    app.use(express.static("public"));

    app.get("/api/stream-info", (req, res) => {
      res.json({
        streamName: this.streamName,
        connected: !!this.receiver,
        clients: this.clients.size,
      });
    });

    app.listen(this.port, () => {
      console.log(`NDI-WebRTC Bridge running on port ${this.port}`);
    });
  }
}

// Start the bridge
const bridge = new NDIWebRTCBridge({
  streamName: "TouchDesigner_Stream",
  port: 8080,
  wsPort: 8081,
});
```

#### Option C: Using Existing NDI-WebRTC Solutions

**1. NDI Bridge by NewTek/Vizrt:**

bash

```bash
# Commercial solution with WebRTC output
# Configure NDI Bridge settings:
Input: TouchDesigner NDI Stream
Output: WebRTC (WHIP/WHEP protocol)
Quality: Ultra Low Latency
Resolution: 1920x1080@30fps
```

**2. OBS.Live NDI Integration:**

javascript

```javascript
// Using OBS.Live API
const obsLive = new OBSLive({
  apiKey: "your-api-key",
  streamKey: "your-stream-key",
});

// Configure NDI input
obsLive.addSource({
  type: "ndi_source",
  name: "TouchDesigner_Stream",
  settings: {
    source_name: "TouchDesigner_Stream",
    bandwidth: "highest",
    sync: "source_timing",
  },
});
```

### Step 3: Web Client Implementation

#### Basic HTML5 Video Client

html

```html
<!DOCTYPE html>
<html>
  <head>
    <title>TouchDesigner NDI Stream</title>
    <style>
      body {
        margin: 0;
        background: #000;
        display: flex;
        justify-content: center;
        align-items: center;
        height: 100vh;
      }

      #video-container {
        position: relative;
        max-width: 100vw;
        max-height: 100vh;
      }

      #stream-video {
        width: 100%;
        height: auto;
        border-radius: 8px;
      }

      #stream-info {
        position: absolute;
        top: 10px;
        left: 10px;
        color: white;
        background: rgba(0, 0, 0, 0.7);
        padding: 10px;
        border-radius: 4px;
        font-family: monospace;
      }

      .controls {
        position: absolute;
        bottom: 10px;
        left: 50%;
        transform: translateX(-50%);
        display: flex;
        gap: 10px;
      }

      button {
        padding: 8px 16px;
        background: #007bff;
        color: white;
        border: none;
        border-radius: 4px;
        cursor: pointer;
      }

      button:hover {
        background: #0056b3;
      }

      .quality-selector {
        margin-left: 10px;
      }
    </style>
  </head>
  <body>
    <div id="video-container">
      <canvas id="stream-video" width="1920" height="1080"></canvas>

      <div id="stream-info">
        <div>Status: <span id="connection-status">Connecting...</span></div>
        <div>FPS: <span id="fps-counter">0</span></div>
        <div>Latency: <span id="latency">-</span>ms</div>
        <div>Quality: <span id="quality">High</span></div>
      </div>

      <div class="controls">
        <button onclick="toggleStream()">Play/Pause</button>
        <button onclick="toggleFullscreen()">Fullscreen</button>
        <select class="quality-selector" onchange="changeQuality(this.value)">
          <option value="high">High Quality</option>
          <option value="medium">Medium Quality</option>
          <option value="low">Low Latency</option>
        </select>
      </div>
    </div>

    <script>
      class NDIStreamClient {
        constructor() {
          this.canvas = document.getElementById("stream-video");
          this.ctx = this.canvas.getContext("2d");
          this.ws = null;
          this.isPlaying = false;
          this.frameCount = 0;
          this.lastFrameTime = Date.now();
          this.latencyHistory = [];

          this.connect();
          this.setupStats();
        }

        connect() {
          this.ws = new WebSocket("ws://localhost:8081");

          this.ws.onopen = () => {
            console.log("Connected to NDI stream");
            document.getElementById("connection-status").textContent =
              "Connected";
            this.isPlaying = true;

            // Request initial frame
            this.ws.send(
              JSON.stringify({
                type: "request-frame",
              })
            );
          };

          this.ws.onmessage = (event) => {
            const data = JSON.parse(event.data);
            if (data.type === "video-frame") {
              this.handleVideoFrame(data);
            }
          };

          this.ws.onclose = () => {
            console.log("Disconnected from NDI stream");
            document.getElementById("connection-status").textContent =
              "Disconnected";
            this.isPlaying = false;

            // Auto-reconnect after 3 seconds
            setTimeout(() => this.connect(), 3000);
          };

          this.ws.onerror = (error) => {
            console.error("WebSocket error:", error);
            document.getElementById("connection-status").textContent = "Error";
          };
        }

        handleVideoFrame(frameData) {
          if (!this.isPlaying) return;

          const img = new Image();
          img.onload = () => {
            // Clear canvas and draw new frame
            this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);
            this.ctx.drawImage(
              img,
              0,
              0,
              this.canvas.width,
              this.canvas.height
            );

            // Update stats
            this.updateStats(frameData.timestamp);
          };

          img.src = frameData.data;
        }

        updateStats(frameTimestamp) {
          const now = Date.now();
          const latency = now - frameTimestamp;

          // Update FPS
          this.frameCount++;
          if (now - this.lastFrameTime >= 1000) {
            const fps = this.frameCount;
            document.getElementById("fps-counter").textContent = fps;
            this.frameCount = 0;
            this.lastFrameTime = now;
          }

          // Update latency (rolling average)
          this.latencyHistory.push(latency);
          if (this.latencyHistory.length > 10) {
            this.latencyHistory.shift();
          }

          const avgLatency =
            this.latencyHistory.reduce((a, b) => a + b, 0) /
            this.latencyHistory.length;
          document.getElementById("latency").textContent =
            Math.round(avgLatency);
        }

        setupStats() {
          // Monitor connection quality
          setInterval(() => {
            if (this.ws && this.ws.readyState === WebSocket.OPEN) {
              this.ws.send(
                JSON.stringify({
                  type: "ping",
                  timestamp: Date.now(),
                })
              );
            }
          }, 5000);
        }

        changeQuality(quality) {
          if (this.ws && this.ws.readyState === WebSocket.OPEN) {
            this.ws.send(
              JSON.stringify({
                type: "change-quality",
                quality: quality,
              })
            );

            document.getElementById("quality").textContent =
              quality.charAt(0).toUpperCase() + quality.slice(1);
          }
        }

        togglePlayback() {
          this.isPlaying = !this.isPlaying;
          if (this.isPlaying) {
            this.ws.send(
              JSON.stringify({
                type: "request-frame",
              })
            );
          }
        }
      }

      // Global functions for controls
      let streamClient;

      window.onload = () => {
        streamClient = new NDIStreamClient();
      };

      function toggleStream() {
        streamClient.togglePlayback();
      }

      function toggleFullscreen() {
        const container = document.getElementById("video-container");
        if (!document.fullscreenElement) {
          container.requestFullscreen();
        } else {
          document.exitFullscreen();
        }
      }

      function changeQuality(quality) {
        streamClient.changeQuality(quality);
      }
    </script>
  </body>
</html>
```

### Step 4: Advanced WebRTC Integration

#### Using WebRTC for Ultra-Low Latency

javascript

```javascript
// webrtc-ndi-client.js
class WebRTCNDIClient {
  constructor() {
    this.pc = new RTCPeerConnection({
      iceServers: [
        { urls: "stun:stun.l.google.com:19302" },
        { urls: "stun:stun1.l.google.com:19302" },
      ],
    });

    this.dataChannel = null;
    this.setupPeerConnection();
  }

  async setupPeerConnection() {
    // Create data channel for control messages
    this.dataChannel = this.pc.createDataChannel("control", {
      ordered: true,
    });

    this.dataChannel.onopen = () => {
      console.log("Data channel opened");
      this.requestNDIStream();
    };

    this.dataChannel.onmessage = (event) => {
      const data = JSON.parse(event.data);
      this.handleControlMessage(data);
    };

    // Handle incoming stream
    this.pc.ontrack = (event) => {
      console.log("Received remote stream");
      const video = document.getElementById("stream-video");
      video.srcObject = event.streams[0];
    };

    // Handle ICE candidates
    this.pc.onicecandidate = (event) => {
      if (event.candidate) {
        this.sendSignalingMessage({
          type: "ice-candidate",
          candidate: event.candidate,
        });
      }
    };
  }

  async requestNDIStream() {
    try {
      // Create offer
      const offer = await this.pc.createOffer();
      await this.pc.setLocalDescription(offer);

      // Send offer to signaling server
      this.sendSignalingMessage({
        type: "offer",
        sdp: offer,
      });
    } catch (error) {
      console.error("Error creating offer:", error);
    }
  }

  sendSignalingMessage(message) {
    // Send to your signaling server
    fetch("/api/webrtc-signal", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
      },
      body: JSON.stringify(message),
    });
  }

  handleControlMessage(data) {
    switch (data.type) {
      case "stream-stats":
        this.updateStreamStats(data.stats);
        break;
      case "quality-changed":
        console.log("Quality changed to:", data.quality);
        break;
    }
  }

  updateStreamStats(stats) {
    document.getElementById("bitrate").textContent =
      Math.round(stats.bitrate / 1000) + " kbps";
    document.getElementById(
      "resolution"
    ).textContent = `${stats.width}x${stats.height}`;
  }
}
```

### Step 5: Performance Optimization

#### TouchDesigner NDI Optimization

python

```python
# In TouchDesigner Execute DAT
class NDIOptimizer:
    def __init__(self):
        self.ndi_out = op('ndiout1')
        self.performance_monitor = op('perform1')
        self.target_fps = 30
        self.quality_levels = ['high', 'medium', 'low']
        self.current_quality = 0

    def optimize_based_on_performance(self):
        current_fps = self.performance_monitor['fps']
        cpu_usage = self.performance_monitor['cpuusage']

        # Adjust quality based on performance
        if current_fps < self.target_fps * 0.8:  # 80% of target
            self.decrease_quality()
        elif current_fps > self.target_fps * 0.95 and cpu_usage < 70:
            self.increase_quality()

    def decrease_quality(self):
        if self.current_quality < len(self.quality_levels) - 1:
            self.current_quality += 1
            self.apply_quality_settings()

    def increase_quality(self):
        if self.current_quality > 0:
            self.current_quality -= 1
            self.apply_quality_settings()

    def apply_quality_settings(self):
        quality = self.quality_levels[self.current_quality]

        if quality == 'high':
            self.ndi_out.par.compression = 'none'
            self.ndi_out.par.format = 'bgra8'
        elif quality == 'medium':
            self.ndi_out.par.compression = 'h264'
            self.ndi_out.par.quality = 85
        else:  # low
            self.ndi_out.par.compression = 'h264'
            self.ndi_out.par.quality = 60

        print(f"NDI quality adjusted to: {quality}")

# Initialize optimizer
optimizer = NDIOptimizer()

# Run optimization every 5 seconds
def onFrameEnd(frame):
    if frame % 150 == 0:  # Every 5 seconds at 30fps
        optimizer.optimize_based_on_performance()
```

### Step 6: Monitoring and Debugging

#### NDI Stream Monitor

python

```python
# TouchDesigner monitoring script
def monitor_ndi_stream():
    ndi_out = op('ndiout1')

    stats = {
        'connected': ndi_out.par.connected.eval(),
        'stream_name': ndi_out.par.streamname.eval(),
        'format': ndi_out.par.format.eval(),
        'resolution': f"{ndi_out.par.resolutionw.eval()}x{ndi_out.par.resolutionh.eval()}",
        'fps': ndi_out.par.rate.eval(),
        'compression': ndi_out.par.compression.eval()
    }

    # Log to console
    print(f"NDI Stream Status: {stats}")

    # Send stats to web clients via OSC or WebSocket
    if stats['connected']:
        send_stats_to_web(stats)

    return stats

def send_stats_to_web(stats):
    # Use WebSocket or HTTP to send stats to web interface
    web_dat = op('websocket1')
    if web_dat:
        web_dat.sendText(json.dumps(stats))
```

This detailed Method 3 implementation provides a robust NDI-based solution with multiple integration options, from simple OBS workflows to custom WebRTC implementations. The approach offers professional-grade quality and performance suitable for broadcast and interactive applications.

---
